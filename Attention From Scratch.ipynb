{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b14a83f-516b-43c3-bf29-b3762e540e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4667878f-8e77-4afb-8fd2-623b944b7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import (word_tokenize)\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bef7983-8246-4da6-bcc1-e52f2c4043a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cd50dbe8-de79-473a-b1ee-45480c0fc845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model=10,num_heads=5):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.posi_enc = PositionalEncoding(10,vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.mha = MultiHeadAtten(d_model=d_model,num_heads=5,vocab_size=vocab_size)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForwardNetwork(input_size=10,hidden_size=5,output_size=10)\n",
    "    def forward(self,embed):\n",
    "        # print(self.vocab_size,'self.vocab_size')\n",
    "        embeds_ = self.posi_enc(embed.unsqueeze(1))\n",
    "        mha = self.mha(embeds_.squeeze(1))\n",
    "        embed_layer =self.layer_norm(embeds_.squeeze(1) + mha)\n",
    "        out = self.ffn(embed_layer)\n",
    "        out = out + embed_layer\n",
    "        out = self.layer_norm(out)\n",
    "        return out\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self,input_size=10,hidden_size=5,output_size=10):\n",
    "        super(FeedForwardNetwork,self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out=self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1c1f65ad-8d23-4c4c-98fd-475a28893a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, features:int,dropout:float)->None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LinearNorm(features)\n",
    "    def forward(self,x,sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "        \n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, self_attention:MultiHeadAtten,self_ffn: FeedForwardNetwork)->None:\n",
    "        super().__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.self_ffn = self_ffn\n",
    "        self.residual_blocks = nn.ModuleList([ResidualBlock(features,dropout) for _ in range(2)])\n",
    "        \n",
    "    def forward(self,embed):\n",
    "        out = self.residual_blocks[0](embed, lambda embed: self.self_attention(embed))\n",
    "        out = self.residual_blocks[1](embed,self.FeedForwardNetwork)\n",
    "        return out\n",
    "\n",
    "        \n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, features:int, layers:nn.ModuleList)->None:\n",
    "#         super().__init__()\n",
    "#     def forward(self,x):\n",
    "#         for layer in self.layers:\n",
    "#             x = layer(x, mask)\n",
    "#         return x\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self,d_model:int,hidden_size:int,dropout:float)-> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(d_model,hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size,d_model)\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out=self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, features:int, self_encoder_block:EncoderBlock)->None:\n",
    "        self.self_encoder_block = self_encoder_block\n",
    "    def forward(self,embeds):\n",
    "        embeds = self.self_encoder_block(embeds)\n",
    "        return embeds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8f1169eb-f249-428a-88b6-21fb7bb5201c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultiHeadAtten.__init__() missing 1 required positional argument: 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[208], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m         multi_head \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(Head,Head_weights)\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m multi_head\n\u001b[0;32m---> 52\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel_mha\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m result \u001b[38;5;241m=\u001b[39m model(text_embedding,output_embedding,mask)\n",
      "Cell \u001b[0;32mIn[190], line 4\u001b[0m, in \u001b[0;36mModel_mha.__init__\u001b[0;34m(self, d_model, num_heads, input_size, hidden_size, output_size, vocab_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Model_mha,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m Decoder(d_model, vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(output_tokenizer\u001b[38;5;241m.\u001b[39mget_vocab()), num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(input_size,output_size)\n",
      "Cell \u001b[0;32mIn[203], line 6\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[0;34m(self, vocab_size, d_model, num_heads)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposi_enc \u001b[38;5;241m=\u001b[39m PositionalEncoding(\u001b[38;5;241m10\u001b[39m,vocab_size)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m vocab_size\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmha \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAtten\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(d_model)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn \u001b[38;5;241m=\u001b[39m FeedForwardNetwork(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: MultiHeadAtten.__init__() missing 1 required positional argument: 'dropout'"
     ]
    }
   ],
   "source": [
    "class MultiHeadAtten(nn.Module):\n",
    "    def __init__(self,d_model: int,num_heads:int,vocab_size:int,dropout):\n",
    "        super(MultiHeadAtten,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.m = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def initialize_weights(self,input_size,output_size):\n",
    "    # Initialize weights with random values from a normal distribution\n",
    "        weights = torch.rand(input_size, output_size)\n",
    "        return weights\n",
    "    \n",
    "    def forward(self,x, encoder_out=None, mask=None):\n",
    "        if encoder_out == None:\n",
    "            Q = K = V = x\n",
    "        else:\n",
    "            Q = x\n",
    "            K = V = encoder_out\n",
    "            \n",
    "            pad_size = K.size(0) - Q.size(0)\n",
    "\n",
    "            Q = F.pad(Q, (0, 0, 0, pad_size), \"constant\", 0)\n",
    "\n",
    "        d_k = self.d_model / self.num_heads\n",
    "        query_weights = self.initialize_weights(self.d_model,self.d_model)\n",
    "\n",
    "        # Initialize weights for key matrix\n",
    "        key_weights = self.initialize_weights(self.d_model,self.d_model)\n",
    "        \n",
    "        # Initialize weights for value matrix\n",
    "        value_weights = self.initialize_weights(self.d_model,self.d_model)\n",
    "        Q_,K_,V_ = torch.matmul(Q,query_weights),torch.matmul(K,key_weights),torch.matmul(V,value_weights)\n",
    "        Q_split = Q_.view(self.num_heads,10 , 10 // self.num_heads)\n",
    "        K_split = K_.view(self.num_heads,10 , 10 // self.num_heads)\n",
    "        V_split = V_.view(self.num_heads,10 , 10 // self.num_heads)\n",
    "        heads = []\n",
    "        for i in range(len(Q_split)):\n",
    "            scaled_dot_product = torch.matmul(Q_split[i],K_split[i].T)/np.sqrt(d_k)\n",
    "            if mask is not None:\n",
    "                print(scaled_dot_product.shape,mask.shape,'shape')\n",
    "                scaled_dot_product = scaled_dot_product.masked_fill(mask==0,float('-inf'))\n",
    "            attn_weights = self.m(scaled_dot_product)\n",
    "            heads.append(torch.matmul(attn_weights,V_split[i]))\n",
    "        heads = torch.stack(heads)\n",
    "        Head = heads.view(self.num_heads * 2, 10)\n",
    "        # print(Head.shape,'head')\n",
    "        \n",
    "        Head_weights = self.initialize_weights(int(self.num_heads * d_k),self.d_model)\n",
    "        multi_head = torch.matmul(Head,Head_weights)\n",
    "        return multi_head\n",
    "model = Model_mha(d_model=10, num_heads=5,input_size=10,hidden_size=5,output_size=10)\n",
    "result = model(text_embedding,output_embedding,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6e090a93-ae2a-4f62-8105-ce5302f5408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(vocab_size, d_model)\n",
    "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self,input_size=10,hidden_size=5,output_size=10):\n",
    "        super(FeedForwardNetwork,self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out=self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,d_model, vocab_size, num_heads=5,input_size=10,hidden_size=5,output_size=10):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.posi_enc = PositionalEncoding(d_model, vocab_size)\n",
    "        self.masked_mha = MultiHeadAtten(d_model,num_heads,vocab_size=vocab_size)\n",
    "        self.mha = MultiHeadAtten(d_model,num_heads)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForwardNetwork(input_size,hidden_size,output_size)\n",
    "\n",
    "    \n",
    "    def forward(self,embeds,encoder_out=None,mask=None):\n",
    "        out_pos = self.posi_enc(embeds.unsqueeze(1))\n",
    "        out = self.masked_mha(out_pos.squeeze(1),mask=mask)\n",
    "        out = out + out_pos.squeeze(1)\n",
    "        out_layer1 = self.layer_norm(out)\n",
    "        out = self.mha(out_layer1,encoder_out=encoder_out)\n",
    "        out = out + out_layer1\n",
    "        out_layer2 = self.layer_norm(out)\n",
    "        out = self.ffn(out_layer2)\n",
    "        out = out + out_layer2\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "37b58761-eacd-48d0-b24f-6e8b53d20a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_mha(nn.Module):\n",
    "    def __init__(self,d_model=10, num_heads=5,input_size=10,hidden_size=5,output_size=10,vocab_size=6):\n",
    "        super(Model_mha,self).__init__()\n",
    "        self.encoder = Encoder(d_model=10,num_heads=5,vocab_size=len(input_tokenizer.get_vocab()))\n",
    "        self.decoder = Decoder(d_model, vocab_size=len(output_tokenizer.get_vocab()), num_heads=5,input_size=10,hidden_size=5,output_size=10)\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "        self.soft = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self,input_embed,output_embed,mask):\n",
    "        encoder_out = self.encoder(input_embed)\n",
    "        decoder_out = self.decoder(output_embed,encoder_out,mask)\n",
    "        return encoder_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "88f88fb7-5577-4c93-9f03-175e563f5724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 10]) xs 10\n",
      "tensor([[[ 1.8733, -0.7064, -0.7422, -0.0855, -1.4620,  0.8337, -0.6678,\n",
      "          -0.3217,  0.2287,  0.9445]],\n",
      "\n",
      "        [[ 0.0674,  0.9699,  1.0701,  0.2637,  0.6719,  0.6149,  1.4483,\n",
      "           1.6997, -0.1566, -0.5222]],\n",
      "\n",
      "        [[ 0.8231, -0.5778,  0.0616, -0.6926,  1.0001,  1.8811, -1.1803,\n",
      "           3.1271, -0.9141,  1.9629]],\n",
      "\n",
      "        [[-0.8954, -1.1705, -0.2625,  0.6475,  0.5567,  1.2419,  0.5073,\n",
      "          -0.5007,  0.6811,  0.4418]],\n",
      "\n",
      "        [[ 1.1115,  0.3736,  0.7952, -0.1086,  1.0646,  1.8434,  0.6801,\n",
      "           0.4552,  0.9872, -1.0676]],\n",
      "\n",
      "        [[-0.1827,  0.4770,  0.1068,  0.7795,  0.7511,  0.6717, -1.1287,\n",
      "           0.4299, -1.4088,  3.0072]],\n",
      "\n",
      "        [[-0.0433,  2.8450,  0.2376,  0.7353, -0.0384,  1.1251, -0.8960,\n",
      "           1.8136,  1.4383,  0.0657]],\n",
      "\n",
      "        [[ 0.8670, -0.2937,  1.2638,  0.4001, -0.4729,  1.2050,  0.0885,\n",
      "          -1.5180, -0.0688,  1.6233]],\n",
      "\n",
      "        [[ 1.9604,  0.5907,  0.8830, -1.6707,  0.7589,  2.3515, -0.9982,\n",
      "           0.6944,  0.9869, -0.1768]],\n",
      "\n",
      "        [[ 1.3832, -0.1749,  0.9181, -1.8251,  0.7834,  2.3462, -0.9942,\n",
      "           0.6943,  0.9875, -0.1768]]], grad_fn=<AddBackward0>) xs1\n",
      "torch.Size([10, 1, 10]) xs 10\n",
      "tensor([[[-0.0606, -0.1231, -2.4640,  1.7840, -0.8466,  0.6739,  0.2549,\n",
      "           2.4404, -0.1418,  2.1874]],\n",
      "\n",
      "        [[ 0.2200,  1.4792,  0.9357,  1.5260, -0.2225, -0.1408,  0.1344,\n",
      "          -0.5249, -0.2480,  0.4155]],\n",
      "\n",
      "        [[-0.4806,  0.2944,  1.8422,  1.1485,  0.0109,  0.6168, -0.2717,\n",
      "           0.1652,  1.6996,  1.7487]],\n",
      "\n",
      "        [[-2.4101,  0.3593,  1.3647,  0.5568,  0.9143,  1.3048, -0.8185,\n",
      "           0.1271, -2.6082,  0.4530]],\n",
      "\n",
      "        [[ 0.1735,  0.3686, -0.9958,  1.6045,  0.9506,  1.3901, -1.2008,\n",
      "           1.0301, -0.0667,  1.6516]],\n",
      "\n",
      "        [[-0.3087,  0.6910,  0.1255,  2.9102, -1.4370, -0.8741,  1.3844,\n",
      "           2.4609,  1.1890,  0.2987]],\n",
      "\n",
      "        [[ 0.7539, -0.9312, -0.6420,  1.6517,  1.7415,  0.7130,  0.6083,\n",
      "           1.4108, -0.4063,  1.3535]],\n",
      "\n",
      "        [[ 1.6903, -1.1375, -0.5605,  1.5160,  1.7663,  0.7090,  0.6123,\n",
      "           1.4107, -0.4057,  1.3535]],\n",
      "\n",
      "        [[ 2.0226, -2.0369, -0.5015,  1.3691,  1.7910,  0.7043,  0.6163,\n",
      "           1.4106, -0.4051,  1.3535]],\n",
      "\n",
      "        [[ 1.4454, -2.8025, -0.4664,  1.2147,  1.8156,  0.6989,  0.6202,\n",
      "           1.4105, -0.4044,  1.3535]]], grad_fn=<AddBackward0>) xs1\n",
      "torch.Size([10, 10]) torch.Size([10, 10]) shape\n",
      "torch.Size([10, 10]) torch.Size([10, 10]) shape\n",
      "torch.Size([10, 10]) torch.Size([10, 10]) shape\n",
      "torch.Size([10, 10]) torch.Size([10, 10]) shape\n",
      "torch.Size([10, 10]) torch.Size([10, 10]) shape\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAtten(nn.Module):\n",
    "    def __init__(self,d_model = 10,num_heads=5,vocab_size=6):\n",
    "        super(MultiHeadAtten,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.m = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def initialize_weights(self,input_size,output_size):\n",
    "    # Initialize weights with random values from a normal distribution\n",
    "        weights = torch.rand(input_size, output_size)\n",
    "        return weights\n",
    "    \n",
    "    def forward(self,x, encoder_out=None, mask=None):\n",
    "        if encoder_out == None:\n",
    "            Q = K = V = x\n",
    "        else:\n",
    "            Q = x\n",
    "            K = V = encoder_out\n",
    "            \n",
    "            pad_size = K.size(0) - Q.size(0)\n",
    "\n",
    "            Q = F.pad(Q, (0, 0, 0, pad_size), \"constant\", 0)\n",
    "\n",
    "        d_k = self.d_model / self.num_heads\n",
    "        query_weights = self.initialize_weights(self.d_model,self.d_model)\n",
    "\n",
    "        # Initialize weights for key matrix\n",
    "        key_weights = self.initialize_weights(self.d_model,self.d_model)\n",
    "        \n",
    "        # Initialize weights for value matrix\n",
    "        value_weights = self.initialize_weights(self.d_model,self.d_model)\n",
    "        Q_,K_,V_ = torch.matmul(Q,query_weights),torch.matmul(K,key_weights),torch.matmul(V,value_weights)\n",
    "        Q_split = Q_.view(self.num_heads,10 , 10 // self.num_heads)\n",
    "        K_split = K_.view(self.num_heads,10 , 10 // self.num_heads)\n",
    "        V_split = V_.view(self.num_heads,10 , 10 // self.num_heads)\n",
    "        heads = []\n",
    "        for i in range(len(Q_split)):\n",
    "            scaled_dot_product = torch.matmul(Q_split[i],K_split[i].T)/np.sqrt(d_k)\n",
    "            if mask is not None:\n",
    "                print(scaled_dot_product.shape,mask.shape,'shape')\n",
    "                scaled_dot_product = scaled_dot_product.masked_fill(mask==0,float('-inf'))\n",
    "            attn_weights = self.m(scaled_dot_product)\n",
    "            heads.append(torch.matmul(attn_weights,V_split[i]))\n",
    "        heads = torch.stack(heads)\n",
    "        Head = heads.view(self.num_heads * 2, 10)\n",
    "        # print(Head.shape,'head')\n",
    "        \n",
    "        Head_weights = self.initialize_weights(int(self.num_heads * d_k),self.d_model)\n",
    "        multi_head = torch.matmul(Head,Head_weights)\n",
    "        return multi_head\n",
    "model = Model_mha(d_model=10, num_heads=5,input_size=10,hidden_size=5,output_size=10)\n",
    "result = model(text_embedding,output_embedding,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fcb2df31-5e4a-4292-b8bd-2b32a65163c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.8785e-01, -1.5043e-01, -1.8734e+00, -1.0219e+00, -7.4881e-01,\n",
       "          6.2113e-01, -3.0642e-02, -3.1917e-01,  1.4463e+00,  1.2891e+00],\n",
       "        [ 1.0103e+00, -2.9173e-01, -1.4029e+00, -1.9209e+00,  5.1360e-01,\n",
       "         -1.9873e-01,  2.1622e-01, -2.2741e-01,  1.4556e+00,  8.4602e-01],\n",
       "        [ 8.8965e-01, -5.8871e-01, -1.4915e+00, -1.6298e+00,  2.9908e-01,\n",
       "         -1.5210e-01, -9.9447e-02, -3.3562e-04,  1.3052e+00,  1.4680e+00],\n",
       "        [ 7.1591e-01, -8.0708e-01, -1.4545e+00, -1.1414e+00,  1.7800e-01,\n",
       "         -1.5304e-01,  2.4323e-01, -6.5507e-01,  1.8105e+00,  1.2634e+00],\n",
       "        [ 1.1063e+00, -4.2132e-01, -1.2921e+00, -1.8655e+00,  5.5175e-01,\n",
       "          2.8650e-01, -1.4560e-02, -4.4940e-01,  1.6230e+00,  4.7534e-01],\n",
       "        [ 7.1090e-01, -2.9867e-01, -1.3932e+00, -1.4643e+00,  5.2168e-01,\n",
       "         -3.0637e-01, -1.9400e-01, -5.2043e-01,  1.0779e+00,  1.8665e+00],\n",
       "        [ 8.4408e-01, -2.6251e-02, -1.4827e+00, -1.7666e+00,  4.6324e-01,\n",
       "         -1.5933e-01, -1.8276e-01, -2.8948e-01,  1.6395e+00,  9.6032e-01],\n",
       "        [ 1.1194e+00, -4.3032e-01, -1.2340e+00, -1.5425e+00,  2.2720e-01,\n",
       "         -9.0586e-02, -4.6906e-02, -7.8573e-01,  1.6223e+00,  1.1612e+00],\n",
       "        [ 1.2808e+00, -3.8211e-01, -1.0526e+00, -1.7767e+00, -2.0953e-01,\n",
       "          2.4196e-01, -1.2176e-01, -5.4270e-01,  1.6372e+00,  9.2544e-01],\n",
       "        [ 1.0927e+00, -6.2936e-01, -1.0135e+00, -1.8250e+00, -7.4003e-02,\n",
       "          3.4402e-01, -4.1541e-02, -4.9994e-01,  1.6187e+00,  1.0279e+00]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "db42f2ec-fd75-40e2-bbe9-1d73fb11f248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'This': 19, 'Natural': 16, 'a': 21, 'learning': 6, 'sequence': 45, 'text': 50, 'data': 26, 'Another': 10, 'dog': 27, '[UNK]': 0, 'lazy': 34, 'learn': 35, 'over': 41, 'training': 52, 'sentence': 8, 'Language': 13, 'models': 38, 'powerful': 42, 'you': 53, '[PAD]': 1, 'here': 32, '[EOS]': 3, 'machine': 37, 'example': 28, 'I': 12, 'to': 51, 'systems': 48, 'for': 7, 'goes': 31, 'Deep': 11, 'the': 9, 'ability': 22, 'quick': 44, 'fascinating': 29, 'love': 36, 'jumps': 33, 'provides': 43, 'Processing': 17, '.': 4, 'an': 23, 'much': 39, 'of': 40, '[SOS]': 2, 'More': 15, 'so': 46, 'Machine': 14, 'subset': 47, 'tasks': 49, 'brown': 25, 'are': 24, 'Transformers': 20, 'fox': 30, 'The': 18, 'is': 5}\n",
      "Vocabulary Size: 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input embeddings\n",
    "text = [\"I love you so much.\",\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another sentence goes here.\",\n",
    "    \"More text data for training.\",\n",
    "    \"Natural Language Processing is fascinating.\",\n",
    "    \"Machine learning provides systems the ability to learn.\",\n",
    "    \"Deep learning is a subset of machine learning.\"\n",
    "    \"Transformers are powerful models for sequence tasks.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"]\n",
    "# Tokenizer setup (optional but recommended for better tokenization)\n",
    "tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\"))\n",
    "trainer = trainers.WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=1)\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "# Train the tokenizer on the corpus\n",
    "tokenizer.train_from_iterator(text, trainer)\n",
    "# Setup decoder and post-processor\n",
    "tokenizer.decoder = decoders.WordPiece()\n",
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"[SOS] $A [EOS]\",\n",
    "    pair=\"[SOS] $A [EOS] [SOS] $B:1 [EOS]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[SOS]\", tokenizer.token_to_id(\"[SOS]\")),\n",
    "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\"))\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Save the tokenizer to disk\n",
    "tokenizer.save(\"wordlevel_tokenizer1.json\")\n",
    "# Print the tokenizer's vocabulary\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Vocabulary Size:\", len(vocab))\n",
    "\n",
    "# Load the tokenizer and use it\n",
    "input_tokenizer = Tokenizer.from_file(\"wordlevel_tokenizer1.json\")\n",
    "\n",
    "# Encode some text with padding\n",
    "encoded = input_tokenizer.encode(\"I love you so much.\")\n",
    "# print(\"Tokens:\", encoded.tokens)\n",
    "\n",
    "# Assuming you want to pad the sequence to a fixed length (e.g., 10)\n",
    "max_length = 10\n",
    "padding_token = \"[PAD]\"\n",
    "padding_token_id = input_tokenizer.token_to_id(padding_token)\n",
    "\n",
    "# Add padding\n",
    "padded_tokens = encoded.tokens + [padding_token] * (max_length - len(encoded.tokens))\n",
    "# print(\"Padded Tokens:\", padded_tokens)\n",
    "\n",
    "# Convert padded tokens back to IDs\n",
    "padded_ids = [input_tokenizer.token_to_id(token) for token in padded_tokens]\n",
    "# print(\"Padded Token IDs:\", padded_ids)\n",
    "\n",
    "embeddings = nn.Embedding(num_embeddings=len(input_tokenizer.get_vocab()),embedding_dim=embedding_dim)\n",
    "indices_tensor = torch.tensor(padded_ids)\n",
    "text_embedding = embeddings(indices_tensor) \n",
    "\n",
    "text_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6814beea-fabc-4106-a2d1-abc130259a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [\"Ti amp molto\",\n",
    "         \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
    "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\",\n",
    "]\n",
    "tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\"))\n",
    "trainer = trainers.WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=1)\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "tokenizer.train_from_iterator(output, trainer)\n",
    "# Setup decoder and post-processor\n",
    "tokenizer.decoder = decoders.WordPiece()\n",
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"[SOS] $A [EOS]\",\n",
    "    pair=\"[SOS] $A [EOS] [SOS] $B:1 [EOS]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[SOS]\", tokenizer.token_to_id(\"[SOS]\")),\n",
    "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\"))\n",
    "    ],\n",
    ")\n",
    "# Save the tokenizer to disk\n",
    "tokenizer.save(\"wordlevel_tokenizer2.json\")\n",
    "\n",
    "# Load the tokenizer and use it\n",
    "output_tokenizer = Tokenizer.from_file(\"wordlevel_tokenizer2.json\")\n",
    "\n",
    "# Print the tokenizer's vocabulary\n",
    "vocab = output_tokenizer.get_vocab()\n",
    "\n",
    "encoded = output_tokenizer.encode(\"Ti amp molto.\")\n",
    "\n",
    "max_length = 10\n",
    "padding_token = \"[PAD]\"\n",
    "padding_token_id = output_tokenizer.token_to_id(padding_token)\n",
    "\n",
    "# Add padding\n",
    "padded_tokens = encoded.tokens + [padding_token] * (max_length - len(encoded.tokens))\n",
    "# print(\"Padded Tokens:\", padded_tokens)\n",
    "\n",
    "# Convert padded tokens back to IDs\n",
    "padded_ids = [output_tokenizer.token_to_id(token) for token in padded_tokens]\n",
    "# print(\"Padded Token IDs:\", padded_ids)\n",
    "\n",
    "output_embeddings = nn.Embedding(num_embeddings=len(output_tokenizer.get_vocab()),embedding_dim=embedding_dim)\n",
    "indices_tensor = torch.tensor(padded_ids)\n",
    "output_embedding = output_embeddings(indices_tensor)\n",
    "\n",
    "mask = torch.eye(10, dtype=torch.bool) | ~(torch.triu(torch.ones(10, 10)) == 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
